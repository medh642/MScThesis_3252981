{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0805ec",
   "metadata": {},
   "source": [
    "## API Ingestion \n",
    "This file describes how metadata from API endpoints can be ingested for retrieval.\n",
    "It also provides code for enriching this metadata with LLM -> to generate summaries and keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### These code snippets can be added later to Ingestion_Ext.py \n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def extract_api_metadata(api_url):\n",
    "    \"\"\"\n",
    "    Extracts metadata from PDOK / WFS / WMS / REST endpoints.\n",
    "    Returns structured metadata or None if invalid/unavailable.\n",
    "    \"\"\"\n",
    "    metadata = {\"url\": api_url, \"type\": \"api_endpoint\", \"valid\": False}\n",
    "    try:\n",
    "        # Normalize URL\n",
    "        api_url = api_url.strip()\n",
    "        if not re.match(r'^https?://', api_url):\n",
    "            print(f\"[WARN] Invalid URL format: {api_url}\")\n",
    "            metadata[\"error\"] = \"Invalid URL format\"\n",
    "            return metadata\n",
    "\n",
    "        # Identify service type\n",
    "        lower_url = api_url.lower()\n",
    "        if \"wfs\" in lower_url:\n",
    "            service_type = \"WFS\"\n",
    "        elif \"wms\" in lower_url:\n",
    "            service_type = \"WMS\"\n",
    "        elif \"wmts\" in lower_url:\n",
    "            service_type = \"WMTS\"\n",
    "        else:\n",
    "            service_type = \"REST/Unknown\"\n",
    "\n",
    "        metadata[\"service_type\"] = service_type\n",
    "\n",
    "        # Try requesting capabilities for OGC services\n",
    "        if service_type in [\"WFS\", \"WMS\", \"WMTS\"]:\n",
    "            if \"GetCapabilities\" not in api_url:\n",
    "                sep = \"&\" if \"?\" in api_url else \"?\"\n",
    "                api_url = f\"{api_url}{sep}service={service_type}&request=GetCapabilities\"\n",
    "            \n",
    "            r = requests.get(api_url, timeout=10)\n",
    "            if r.status_code != 200:\n",
    "                metadata[\"error\"] = f\"HTTP {r.status_code}\"\n",
    "                return metadata\n",
    "\n",
    "            xml_root = ET.fromstring(r.text)\n",
    "            ns = {\"wms\": \"http://www.opengis.net/wms\", \n",
    "                  \"wfs\": \"http://www.opengis.net/wfs\", \n",
    "                  \"ows\": \"http://www.opengis.net/ows\"}\n",
    "\n",
    "            # Extract general service info\n",
    "            title = xml_root.find(\".//ows:Title\", ns)\n",
    "            abstract = xml_root.find(\".//ows:Abstract\", ns)\n",
    "            keywords = [kw.text for kw in xml_root.findall(\".//ows:Keyword\", ns)]\n",
    "\n",
    "            metadata.update({\n",
    "                \"valid\": True,\n",
    "                \"title\": title.text if title is not None else None,\n",
    "                \"abstract\": abstract.text if abstract is not None else None,\n",
    "                \"keywords\": keywords,\n",
    "                \"date_ingested\": datetime.now().isoformat(),\n",
    "            })\n",
    "\n",
    "            # Extract available layers (for WFS/WMS)\n",
    "            layers = []\n",
    "            for layer in xml_root.findall(\".//wms:Layer\", ns) or xml_root.findall(\".//wfs:FeatureType\", ns):\n",
    "                lname = layer.find(\".//wms:Name\", ns) or layer.find(\".//wfs:Name\", ns)\n",
    "                if lname is not None:\n",
    "                    layers.append(lname.text)\n",
    "            if layers:\n",
    "                metadata[\"available_layers\"] = layers[:10]\n",
    "\n",
    "        else:\n",
    "            # Fallback for REST APIs: try a GET and parse JSON\n",
    "            r = requests.get(api_url, timeout=10)\n",
    "            if r.status_code == 200 and \"application/json\" in r.headers.get(\"Content-Type\", \"\"):\n",
    "                data = r.json()\n",
    "                metadata.update({\n",
    "                    \"valid\": True,\n",
    "                    \"service_type\": \"REST\",\n",
    "                    \"keys\": list(data.keys())[:10]\n",
    "                })\n",
    "            else:\n",
    "                metadata[\"error\"] = f\"Unrecognized response type: {r.headers.get('Content-Type')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        metadata[\"error\"] = str(e)\n",
    "        print(f\"[WARN] Failed to extract API metadata: {e}\")\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding API ingestion to the existing pipeline (Includes some connection hints and modifications for merging with Ingestion_Ext.py)\n",
    "def ingest_api_endpoints(persist_dir, api_urls):\n",
    "    \"\"\"\n",
    "    Ingests API endpoints (e.g. PDOK WFS/WMS/REST) into ChromaDB\n",
    "    with semantic enrichment.\n",
    "    \"\"\"\n",
    "    os.makedirs(persist_dir, exist_ok=True)\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    client = PersistentClient(path=persist_dir)\n",
    "    coll = client.get_or_create_collection(\"api_layers\")\n",
    "\n",
    "    docs, metas, ids = [], [], []\n",
    "\n",
    "    for api_url in api_urls:\n",
    "        meta = extract_api_metadata(api_url)\n",
    "        if not meta.get(\"valid\", False):\n",
    "            print(f\"[WARN] Skipping invalid API endpoint: {api_url}\")\n",
    "            continue\n",
    "\n",
    "        # Enrich metadata semantically\n",
    "        print(f\"[INFO] Enriching API metadata for {meta.get('title', api_url)}\")\n",
    "        enriched = enrich_metadata(meta)\n",
    "        if enriched:\n",
    "            meta.update(enriched)\n",
    "\n",
    "        doc_text = json.dumps(meta, indent=2)\n",
    "        docs.append(doc_text)\n",
    "        metas.append(meta)\n",
    "        ids.append(make_id(\"api\", api_url))\n",
    "\n",
    "    # Prepare and store embeddings\n",
    "    embeddings = model.encode(docs, convert_to_numpy=True).tolist()\n",
    "    coll.add(documents=docs, metadatas=metas, ids=ids, embeddings=embeddings)\n",
    "    print(f\"[INFO] Ingested {len(docs)} valid API endpoints into 'api_layers'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustments to the main block \n",
    "p.add_argument(\"--api_endpoints\", nargs=\"*\", default=None, help=\"List of WFS/WMS/REST API endpoints to ingest\")\n",
    "\n",
    "if args.api_endpoints:\n",
    "    ingest_api_endpoints(args.persist_dir, args.api_endpoints)\n",
    "\n",
    "# While running on bash: Just simply use the same command + now the API endpoint"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
